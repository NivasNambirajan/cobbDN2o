{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Evaluate model \n",
    "#2. Swap and re-evaluate looping through all swappable variables and compute incremental contribution\n",
    "#3. Parallelize\n",
    "\n",
    "#1. Evaluate model\n",
    "# Read modeling stack, coefficients\n",
    "\n",
    "# Cast data into model matrix by X_ID\n",
    "\n",
    "# Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import time\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Store an intermediate evaluation matrix for quick access\n",
    "\n",
    "\n",
    "Instead of \n",
    "\n",
    "$y = A \\beta$,\n",
    "\n",
    "Can think of this as being split into two operations\n",
    "\n",
    "\n",
    "1. $\\tilde{A} = A \\cdot diag(\\beta)$\n",
    "\n",
    "2. $y = rowsum(\\tilde{A}) $\n",
    "\n",
    "\n",
    "\n",
    "$\\tilde{A} = A \\cdot diag(\\beta)$\n",
    "\n",
    "# 2. Efficient adstock computation using matrix multiplication\n",
    "\n",
    "Just a simple trick to save time.\n",
    "\n",
    "# Notes:\n",
    "1. Map-reduce implementation (pyspark)\n",
    "2. Test specs:\n",
    "\n",
    "    A. THD\n",
    "    \n",
    "    B. Dignity Health\n",
    "    \n",
    "    C. Citi Enterprise\n",
    "    \n",
    "    \n",
    "3. Features to be added:\n",
    "\n",
    "    A. This does not support HALOs yet - LHF\n",
    "    \n",
    "    B. It does not support non-uniform interactions - LHF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Swap and re-evaluate looping through all swappable variables and compute incremental contribution\n",
    "#define a singleModel class\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def npdate2datetime(somedate):\n",
    "    somedate_ts = (np.datetime64(somedate) - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n",
    "    somedate_dt = datetime.utcfromtimestamp(somedate_ts)\n",
    "    return somedate_dt\n",
    "\n",
    "def nearest(items, thisdate):\n",
    "    return min(items, key=lambda x: abs(x - np.datetime64(thisdate)))\n",
    "\n",
    "def suffixToAdstock(suffix):\n",
    "    adstockSpec = int(suffix)\n",
    "    persistence, adstockSpec = (adstockSpec%100)/100, adstockSpec//100\n",
    "    peak, length = adstockSpec%10, adstockSpec//10\n",
    "    return (length, peak, persistence)\n",
    "\n",
    "#computeAdstock takes base var x and params (length, peak, persistence) and returns NormalizedAdstock vector|\n",
    "def computeAdstockVector(x, params):\n",
    "    #print('Length of var: ', x.shape)\n",
    "    wk = 0\n",
    "    l, p, r = params[0], params[1], params[2]\n",
    "    y = []\n",
    "    for i in range(len(x)):\n",
    "        if wk <= l:\n",
    "            if i < p and p > 0:\n",
    "                y.append(i/p)\n",
    "            else:\n",
    "                y.append(np.power(r, i-p))\n",
    "        else:\n",
    "            y.append(0)\n",
    "        wk+=1\n",
    "    \n",
    "    y = np.array(y)/np.sum(y)\n",
    "    y_adstock = y\n",
    "    if l>0:\n",
    "        x = np.insert(x, l+1, x[l])\n",
    "        y = np.insert(y, l+1, 0)\n",
    "    if p==0:\n",
    "        x=np.insert(x, 0, 0)\n",
    "        y=np.insert(y, 0, 0)\n",
    "    #print('Adstock Vector: \\n', y)\n",
    "    #print('Adstock Vector, Raw Adstock Vector, Lengths: ', y.shape, y_adstock.shape)\n",
    "    return y_adstock\n",
    "\n",
    "#takes in base var and normalized adstock values and returns transformed var\n",
    "def computeAdstockedVar(yvar, asvals_53wk):\n",
    "    adstock_matrix = np.zeros((len(yvar), len(yvar)))\n",
    "    for i in range(len(yvar)):\n",
    "        for j in range(len(asvals_53wk)):\n",
    "            if (i+j)<len(yvar):\n",
    "                adstock_matrix[i+j, i] = asvals_53wk[j]\n",
    "            else: break\n",
    "    return np.dot(adstock_matrix, yvar)\n",
    "\n",
    "def invertAdstockedVar(yvar, asvals_53wk):\n",
    "    adstock_matrix = np.zeros((len(yvar), len(yvar)))\n",
    "    for i in range(len(yvar)):\n",
    "        for j in range(len(asvals_53wk)):\n",
    "            if (i+j)<len(yvar):\n",
    "                adstock_matrix[i+j, i] = asvals_53wk[j]\n",
    "            else: break\n",
    "    #print('Adstock Matrix: ', adstock_matrix)\n",
    "    return np.dot(np.linalg.pinv(adstock_matrix), yvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class singleModel():\n",
    "    def __init__(self, estack, coeffs, ocome, thisxid, fbase='FloatingBase'):\n",
    "        self.modelStack = estack\n",
    "        self.modelStack['X_DT'] = pd.to_datetime(self.modelStack['X_DT'])\n",
    "        self.startTime = self.modelStack['X_DT'].min()\n",
    "        self.endTime = self.modelStack['X_DT'].max()\n",
    "        self.coeffs = coeffs\n",
    "        if 'X_ID' in list(self.coeffs['Variable']):\n",
    "            self.intercept = self.coeffs.loc[self.coeffs['Variable']=='X_ID', 'Coefficient']\n",
    "        else:\n",
    "            self.intercept = 0.0\n",
    "        self.coeffMeans = np.array(self.coeffs.loc[self.coeffs['Variable']!='X_ID', 'Coefficient'])\n",
    "        self.coeffMeans = np.append(self.coeffMeans, self.intercept)\n",
    "        self.xid = thisxid\n",
    "        self.outcomeName = ocome\n",
    "        self.modeledVars = list(self.coeffs.loc[self.coeffs['Variable']!='X_ID', 'Variable'])\n",
    "        self.tps = [var for var in self.modeledVars if var.startswith('M_')]\n",
    "        self.fbname = fbase\n",
    "        \n",
    "        self.transformationType, self.varsByTransformation = self.getTransformNames(self.modeledVars)\n",
    "    \n",
    "    def getTransformNames(self, varnames):\n",
    "        self.transformationType={var:'NA' for var in varnames}\n",
    "        self.varsByTransformation = {}\n",
    "        for var in varnames:\n",
    "            varSegments = var.split('_')\n",
    "            adstockSegment = [seg for seg in varSegments if (len(seg)>=4 and len(seg)<=5 and seg.isdigit())]\n",
    "            if adstockSegment:\n",
    "                self.transformationType[var] = adstockSegment[0]\n",
    "                if adstockSegment[0] in self.varsByTransformation.keys():\n",
    "                    self.varsByTransformation[adstockSegment[0]].append(var)\n",
    "                else:\n",
    "                    self.varsByTransformation[adstockSegment[0]] = [var]\n",
    "            elif 'LOGX' in var.split('_'):\n",
    "                self.transformationType[var] = 'LOGX'\n",
    "                if 'LOGX' in self.varsByTransformation.keys():\n",
    "                    self.varsByTransformation['LOGX'].append(var)\n",
    "                else:\n",
    "                    self.varsByTransformation['LOGX']=[var]\n",
    "            elif 'LOGC' in var.split('_'):\n",
    "                self.transformationType[var] = 'LOGC'\n",
    "                if 'LOGC' in self.varsByTransformation.keys():\n",
    "                    self.varsByTransformation['LOGC'].append(var)\n",
    "                else:\n",
    "                    self.varsByTransformation['LOGC'] = [var]\n",
    "            else:\n",
    "                self.transformationType[var] = 'Raw'\n",
    "                if 'Raw' in self.varsByTransformation.keys():\n",
    "                    self.varsByTransformation['Raw'].append(var)\n",
    "                else:\n",
    "                    self.varsByTransformation['Raw'] = [var]\n",
    "                    \n",
    "        return self.transformationType, self.varsByTransformation\n",
    "\n",
    "    \n",
    "    def evaluate(self, stack = None, start=None, end=None): #returns evaluation\n",
    "        if start==None:\n",
    "            start = self.startTime\n",
    "        if end == None:\n",
    "            end = self.endTime\n",
    "        if stack is None:\n",
    "            stack=self.modelStack\n",
    "        y = np.array(stack[self.outcomeName])\n",
    "        X = stack.loc[(stack['X_DT']>=start) & (stack['X_DT']<=end), self.modeledVars].values\n",
    "        b = np.array(self.coeffMeans)\n",
    "        fb = stack[self.fbname]\n",
    "        oneMatrix = np.ones((X.shape[0], X.shape[1]+1))\n",
    "        oneMatrix[:, :-1] = X\n",
    "        X = oneMatrix\n",
    "        del oneMatrix\n",
    "        self.evalMatrix = X.dot(np.diag(b))\n",
    "        self.evaluation = np.exp(X.dot(b)+fb)\n",
    "        return self.evaluation\n",
    "\n",
    "    def getRawContribution(self, varnames, start=None, end=None):\n",
    "        if start == None:\n",
    "            start = self.startTime\n",
    "        if end == None:\n",
    "            end = self.endTime\n",
    "        varIndices = [self.modeledVars.index(varname) for varname in varnames]\n",
    "        evals = self.evaluate(start=start, end=end)\n",
    "        return np.multiply(evals, (1-1/np.exp(np.sum(self.evalMatrix[:, varIndices], axis=1))))\n",
    "    \n",
    "    def getDecompAdjustment(self, start=None, end=None):\n",
    "        if start == None:\n",
    "            start = self.startTime\n",
    "        if end == None:\n",
    "            end = self.endTime\n",
    "        soloTotalContribution = sum([self.getRawContribution([var], start, end).sum() for var in self.tps])\n",
    "        comboTotalContribution = self.getRawContribution(self.tps, start, end).sum()\n",
    "        return comboTotalContribution/soloTotalContribution\n",
    "    \n",
    "    def getDecomps(self, varnames, start=None, end=None):\n",
    "        if start == None:\n",
    "            start = self.startTime\n",
    "        if end == None:\n",
    "            end = self.endTime\n",
    "        rawContribution = self.getRawContribution(varnames, start, end)\n",
    "        tpContribution = self.getRawContribution(varnames)\n",
    "        \n",
    "    def getSwapAdjustment(self, start=None, end=None):\n",
    "        if start == None:\n",
    "            start = self.startTime\n",
    "        if end == None:\n",
    "            end = self.endTime\n",
    "        return 1\n",
    "        \n",
    "    \n",
    "    def getRawSwap(self, varname, focusStart, focusEnd=None):\n",
    "        if focusEnd==None:\n",
    "            focusEnd = self.modelStack['X_DT'].max()\n",
    "        #1. swap out var[focusStart:focusEnd] with var[focusStart-1yr:focusEnd-1yr]\n",
    "        stack = self.modelStack[(self.modelStack['X_DT']>=focusStart) & (self.modelStack['X_DT']<=focusEnd)]\n",
    "        swapStack = stack.copy(deep=True)\n",
    "        focusStart_ts =  (np.datetime64(focusStart) - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n",
    "        focusStart_dt = datetime.utcfromtimestamp(focusStart_ts)\n",
    "        swapStart = np.datetime64(focusStart_dt.replace(year=(focusStart_dt.year)-1))\n",
    "        print('raw swap start:', swapStart)\n",
    "        swapStart = nearest(np.array(self.modelStack['X_DT'].unique()), swapStart)\n",
    "        print('stacked swap start:', swapStart)\n",
    "        swapEnd = focusEnd.replace(year=(focusEnd.year)-1)\n",
    "        swapEnd = nearest(np.array(self.modelStack['X_DT'].unique()), swapEnd)\n",
    "        print(len(swapStack))\n",
    "        print(len(np.array(self.modelStack.loc[(self.modelStack['X_DT']>=swapStart)&(self.modelStack['X_DT']<=swapEnd)])))\n",
    "        swapStack.loc[:, varname] = np.array(self.modelStack.loc[(self.modelStack['X_DT']>=swapStart)&(self.modelStack['X_DT']<=swapEnd), varname])\n",
    "        \n",
    "        #2. compute raw swap\n",
    "        swappedEvals = self.evaluate(stack=swapStack, start=stack['X_DT'].min(), end=stack['X_DT'].max()).sum()\n",
    "        evals = self.evaluate(stack=stack, start=stack['X_DT'].min(), end=stack['X_DT'].max()).sum()\n",
    "        return evals-swappedEvals\n",
    "        \n",
    "    #just invert the adstock to get halfInverted transformed vars - scalars intact. \n",
    "    #vars just unlogged and inverse-Adstocked\n",
    "    #can be replaced with scalars and raw stacked vars to be more efficient\n",
    "    def getHalfBakedStack(self):\n",
    "        self.halfBakedStack = self.modelStack.copy(deep=True)\n",
    "        for transformType in self.varsByTransformation.keys():\n",
    "            if transformType.isdigit():\n",
    "                for var in self.varsByTransformation[transformType]:\n",
    "                    self.halfBakedStack.loc[:, var] = np.exp(self.halfBakedStack[var])\n",
    "                    self.halfBakedStack.loc[:, var] = self.halfBakedStack.loc[:, var] - 1\n",
    "                    #print('Debug: ', self.halfBakedStack.loc[:, var])\n",
    "                    adstockParams = suffixToAdstock(transformType)\n",
    "                    #print('Length, Peak, Persistence: ', adstockParams)\n",
    "                    adstockVector = computeAdstockVector(np.array(self.halfBakedStack[var]), adstockParams)\n",
    "                    self.halfBakedStack.loc[:, var] = invertAdstockedVar(np.array(self.halfBakedStack[var]), adstockVector)\n",
    "                    newVar = '_'.join(var.split('_')[:-1]+['HFBK'])\n",
    "                    self.halfBakedStack.rename(columns={var:newVar}, inplace=True)\n",
    "        return self.halfBakedStack\n",
    "        \n",
    "    def induceZeros(self, varnames, start=None, end=None):\n",
    "        if start==None:\n",
    "            start = self.startTime\n",
    "        if end==None:\n",
    "            end = self.endTime\n",
    "        #paste code for adstock*indicator_matrix*inverse_adstock*var here\n",
    "        #note that Adstocked(var)(t) is only dependent on var(s) for s<=t. So if \n",
    "        for var in varnames:\n",
    "            varHfbk = '_'.join(var.split('_')[:-1]+['HFBK'])\n",
    "            suffix = var.split('_')[-1]\n",
    "            if varHfbk in list(self.halfBakedStack):\n",
    "                self.halfBakedStack[var] = self.halfBakedStack[varHfbk]\n",
    "                self.halfBakedStack.loc[(self.halfBakedStack['X_DT']>=start)&(self.halfBakedstack['X_DT']<=end), var] = 0\n",
    "                if suffix.isdigit():\n",
    "                    adstockParams = suffixToAdstock(suffix)\n",
    "                    adstockVector = computeAdstockVector(np.array(self.halfBakedStack[var]), adstockParams)\n",
    "                    self.halfBakedStack.loc[:, var] = computeAdstockedVar(np.array(self.halfBakedStack[var]), adstockVector)\n",
    "                else:\n",
    "                    self.halfBakedStack.loc[(self.halfBakedStack['X_DT']>=start)&(self.halfBakedstack['X_DT']<=end), var] = 1\n",
    "            else:\n",
    "                print('Error. ', var, ' Not in stack.')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nnambira\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5000500679016113  seconds to run partial MOR for single XID\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "xidmodel = singleModel(estack_xid1, coeffs_xid1, outcome, 'XRT')\n",
    "#pprint(xidmodel.transformationType)\n",
    "#pprint(xidmodel.varsByTransformation)\n",
    "xidmodel.getHalfBakedStack()\n",
    "evals = xidmodel.evaluate()\n",
    "decompDict = {var:xidmodel.getRawContribution([var]).sum() for var in list(xidmodel.modeledVars) if var.startswith('M_')}\n",
    "#print(decompDict)\n",
    "print(time.time() - start, ' seconds to run partial MOR for single XID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'focusStart' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-22f1203a174e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxidmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetRawSwap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'M_NP_N_PRD_IMP_8030'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfocusStart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfocusStart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'focusStart' is not defined"
     ]
    }
   ],
   "source": [
    "xidmodel.getRawSwap('M_NP_N_PRD_IMP_8030', focusStart = focusStart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X_DT X_ID  D_HOLDOUT X_PRD  D_PR_UV  D_VALID_BOTH  D_VALID_XRT  \\\n",
      "0  2014-01-06  RET          0   RET        0             1            0   \n",
      "1  2014-01-13  RET          0   RET        0             1            0   \n",
      "2  2014-01-20  RET          0   RET        0             1            0   \n",
      "3  2014-01-27  RET          0   RET        0             1            0   \n",
      "4  2014-02-03  RET          0   RET        0             1            0   \n",
      "\n",
      "   D_VALID_RET  log_C_CAL_NEW_INB_CNT  C_GQV_RET_TRP_GIX_LOGX  \\\n",
      "0            1               7.459915                0.092082   \n",
      "1            1               7.474772                0.086673   \n",
      "2            1               7.406103                0.079475   \n",
      "3            1               7.499977                0.077930   \n",
      "4            1               7.361375                0.071162   \n",
      "\n",
      "             ...             M_SM_FB_IMP_8120  M_SM_FB_IMRE_IMP_8120  \\\n",
      "0            ...                     0.033718                    0.0   \n",
      "1            ...                     0.029478                    0.0   \n",
      "2            ...                     0.029545                    0.0   \n",
      "3            ...                     0.046413                    0.0   \n",
      "4            ...                     0.086799                    0.0   \n",
      "\n",
      "   M_SM_IG_IMP_8120  M_SM_IG_IMRE_IMP_8120  M_SM_LI_IMP_8120  \\\n",
      "0               0.0                    0.0               0.0   \n",
      "1               0.0                    0.0               0.0   \n",
      "2               0.0                    0.0               0.0   \n",
      "3               0.0                    0.0               0.0   \n",
      "4               0.0                    0.0               0.0   \n",
      "\n",
      "   M_SM_TW_IMP_8120  M_SM_TW_IMRE_IMP_8120  M_TV_BRD_GRP_13280  \\\n",
      "0               0.0                    0.0            1.882014   \n",
      "1               0.0                    0.0            1.717498   \n",
      "2               0.0                    0.0            1.535315   \n",
      "3               0.0                    0.0            1.255988   \n",
      "4               0.0                    0.0            0.968985   \n",
      "\n",
      "   SC_CALNEW_OVER_CWWNST_LOG  SC_CALNEW_OVER_WESVS_LOG  \n",
      "0                  -0.243225                 -0.065311  \n",
      "1                  -0.230606                 -0.046526  \n",
      "2                  -0.168726                 -0.007834  \n",
      "3                  -0.216183                 -0.069491  \n",
      "4                  -0.291071                 -0.119114  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "estack = pd.read_csv('Documents/MPI/troweInbCalls/estack.csv')\n",
    "print(estack.head())\n",
    "\n",
    "coeffs = pd.read_csv('Documents/MPI/troweInbCalls/coeffs.csv')\n",
    "#coeffs['X_ID'] = ['|'.join([val1, val2, val3]) for (val1, val2, val3) in zip(list(coeffs['InteractionValue3']), list(coeffs['InteractionValue1']), list(coeffs['InteractionValue2']))]\n",
    "coeffs['X_ID'] = coeffs['InteractionValue1']\n",
    "#get fixed effect\n",
    "#coeffs.loc[coeffs['Type']=='FE', 'X_ID'] = coeffs['InteractionValue1']\n",
    "\n",
    "\n",
    "fbase = pd.read_csv('Documents/MPI/troweInbCalls/floatingBase.csv')\n",
    "fbase.drop('RowIndex', axis=1, inplace=True)\n",
    "\n",
    "fbase['X_DT']=pd.to_datetime(fbase['X_DT'])\n",
    "estack['X_DT'] = pd.to_datetime(estack['X_DT'])\n",
    "\n",
    "estack = pd.merge(estack, fbase, on=['X_ID', 'X_DT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "estack_xid1 = estack[estack['X_ID']=='XRT']\n",
    "coeffs_xid1 = coeffs[coeffs['X_ID']=='XRT']\n",
    "outcome = coeffs['DepVar'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nnambira\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2017-01-02T00:00:00.000000')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focusStart = estack['X_DT'].unique()[-13]\n",
    "#focusStart =  (focusStart - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n",
    "focusStart_ts =  (focusStart - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n",
    "focusStart = datetime.utcfromtimestamp(focusStart_ts)\n",
    "np.datetime64(focusStart)\n",
    "#blahStart = focusStart.replace(year=focusStart.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M_MG_N_BRD_IMP_8140': 13.254581730729342, 'M_MG_N_PRD_IMP_8140': 21.232735691891904, 'M_NP_N_BRD_IMP_8030': 37.201963462573985, 'M_NP_N_PRD_IMP_8030': 14.02115113538105, 'M_OD_IMP_8020': 29.214871684221762, 'M_OD_PG_BRD_CLK_8020': 0.38878820709256684, 'M_OD_PG_PRD_CLK_8020': 18.2803634424547, 'M_OD_SS_BRD_CLK_8020': 3.0217599488163525, 'M_OD_SS_PRD_CLK_8020': 18.693517658022554, 'M_OV_RET_IMP_8010': 0.9965775410842174, 'M_OV_XRT_IMP_8010': 6.8389761827815025, 'M_PS_BRD_CLK_8010': 56.47415366435719, 'M_PS_PRD_CLK_8010': 74.42101821072008, 'M_RD_BRD_IMP_8160': 56.252984560300575, 'M_RD_PRD_IMP_8160': 0.0, 'M_SM_FB_IMP_8120': 6.4045147303754595, 'M_SM_FB_IMRE_IMP_8120': 0.8533027129662888, 'M_SM_IG_IMP_8120': 0.1269610679497038, 'M_SM_IG_IMRE_IMP_8120': 1.7078733584524621, 'M_SM_LI_IMP_8120': 2.443244136370027, 'M_SM_TW_IMP_8120': 5.0849909768507375, 'M_SM_TW_IMRE_IMP_8120': 0.9008757667350826, 'M_TV_BRD_GRP_13280': 142.97427700318713}\n"
     ]
    }
   ],
   "source": [
    "evals = xidmodel.evaluate()\n",
    "decompDict = {var:xidmodel.getRawContribution([var]).sum() for var in list(xidmodel.modeledVars) if var.startswith('M_')}\n",
    "print(decompDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9730149246881088"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xidmodel.getDecompAdjustment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xidmodel.rawDecomp([var for var in list(xidmodel.modeledVars) if var.startswith('M_')]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(decompDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = estack['X_DT'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2014-01-06 00:00:00')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2013-01-06 00:00:00')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdate=date.replace(year=(date.year)-1)\n",
    "newdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(coeffs_xid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estack.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.plot(np.exp(np.array(estack_xid1[outcome])))\n",
    "plt.plot(np.array(evals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def getResults(xid):\n",
    "    global estack\n",
    "    global coeffs\n",
    "    estack_xid1 = estack[estack['X_ID']==xid]\n",
    "    coeffs_xid1 = coeffs[coeffs['X_ID']==xid]\n",
    "    outcome = coeffs['DepVar'].unique()[0]\n",
    "    xidmodel = singleModel(estack_xid1, coeffs_xid1, outcome, xid)\n",
    "\n",
    "    evals = xidmodel.evaluate()\n",
    "    decompDict = {var:xidmodel.rawDecomp([var]).sum() for var in list(xidmodel.modeledVars) if var.startswith('M_')}\n",
    "    return evals, decompDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(2) as p:\n",
    "    print(p.map(getResults, ['XRT', 'RET']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
